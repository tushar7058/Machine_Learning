{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Linear Regression:\n",
    "\n",
    "Y = wX + b\n",
    "\n",
    "Y --> Dependent Variable\n",
    "\n",
    "X --> Independent Variable\n",
    "\n",
    "w --> weight\n",
    "\n",
    "b --> bias"
   ],
   "id": "262c5eb43f67344b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Gradient Descent:\n",
    "\n",
    "Gradient Descent is an optimization algorithm used for minimizing the loss function in various machine learning algorithms. It is used for updating the parameters of the learning model.\n",
    "\n",
    "w = w - α*dw\n",
    "\n",
    "b = b - α*db"
   ],
   "id": "e945d99e0b10563b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Learning Rate:\n",
    "\n",
    "Learning rate is a tuning parameter in an optimization algorithm that determines the step size at each iteration while moving toward a minimum of a loss function."
   ],
   "id": "a644110488c9ca18"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-10T15:08:34.615297Z",
     "start_time": "2024-06-10T15:08:34.613731Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# importing the libraries\n",
    "import numpy as np"
   ],
   "id": "dbdb83b9614de458",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Linear Regression",
   "id": "c4e38b98d7d230a6"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-10T15:09:15.213834Z",
     "start_time": "2024-06-10T15:09:15.208750Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class Linear_regression(): \n",
    " # initiating parameters(learning rate and no of iterations)\n",
    "    def _inint_(self,learning_rate, no_of_iterations): # for initiating parameters\n",
    "        self.learning_rate = learning_rate\n",
    "        self.no_of_iterations = no_of_iterations\n",
    "\n",
    "    def fit(self,X,Y):\n",
    "        # no of training examples and features\n",
    "        self.m , self.n = X.shape # no of rows and columns\n",
    "        #initiating the weight and Bias(Gradient Descent)\n",
    "        self.w = np.zeros(self.n)\n",
    "        self.b = 0\n",
    "\n",
    "        self.X = X\n",
    "        self.Y = Y\n",
    "\n",
    "        # implementing gradient descent\n",
    "        for i in range(self.no_of_iterations):\n",
    "            self.update_weights()\n",
    "\n",
    "    def update_weights(self,):\n",
    "        Y_prediction = self.predict(self.X)\n",
    "\n",
    "        # calculate gradient\n",
    "        dw =(2*(self.X.T).dot(self.Y-Y_prediction))/self.m\n",
    "        db = 2*np.sum(self.Y-Y_prediction)/self.m\n",
    "\n",
    "\n",
    "        # updating the weights \n",
    "        self.w = self.w - self.learning_rate*dw\n",
    "        self.b = self.b - self.learning_rate*db\n",
    "\n",
    "\n",
    "    def predict(self,X):\n",
    "        return X.dot(self.w)+self.b\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    "
   ],
   "id": "50b484d3599825fb",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "a6080def31586ddf"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
